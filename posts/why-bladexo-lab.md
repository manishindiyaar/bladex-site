---
title: 'Why we started Bladex Lab?'
date: '2024-12-29'
description: 'why do we call it a lab?'
image: '/post_assets/manish.jpg'
tags: ['bladex', 'bladex_lab', 'why_lab']
---
# It is not an agency, not a company, or a business.

# It’s Lab. 

and why do we call it a lab?

You know, when I was in 10th or maybe 11th grade, I often wondered why there weren't any films focused on core subjects like physics or history. I wished for a film that could teach each chapter as an episode, especially in physics. How amazing would that be? 

Everyone would be excited to watch it, and no one would have to put in much effort to learn.

When I look back, I often wonder why those things seemed impossible in the past.

Some of you might say that creating a film requires a lot of money and manpower, right?

However, that has changed in 2024. Now, a person with a story and the determination to make it happen can produce a film alone, and the cost is a fraction—up to 1000 times cheaper—than before.

We are at the forefront of the AI revolution, reimagining the film and media industry.

we are very proud to say that we are not getting left behind.

Every week we experiment with new models, and new workflows and get our hands dirty and the reason is simple we are seeing the vision, a vision that will shape the future generation.

We launched our first film in the last week of July 2024. 

Over the next 30 days, we dedicated 7-8 hours daily to this project. During that time, we began learning about diffusion models, and a new open-source model called Flux was released, which we experimented with as well. We learned how to train voices and maintain consistency in the images. We also started using ComfyUI and began writing my story script. After a month of hard work, we successfully uploaded the film on YT. Although it did not look like a film, I was satisfied with that because I got a taste of the future of the media industry.

It was all just experimentation.

Similarly, let me share another story. I come from a very underprivileged, tier-3 village, where advanced technology like smartphones was rare. The first time I saw a smartphone interacting with a human, I was amazed (I didn’t realize it was just Google Assistant). The way I felt at that moment is one of the reasons why I am working on these types of projects. 

I’ve been involved with large language models (LLMs) for quite a while, and it’s all about interacting with users through conversation.

I’m grateful that I’ve been able to experiment with this technology, which has fascinated me since my childhood.

When AI was emerging, I started from reading research papers to building apps with ai, i went all the way.

As large language models (LLMs) improved, new features were introduced, including function calling. This means we can invoke external APIs or data within the LLM's input or output as JSON. While this may seem straightforward, it marks the beginning of a new era—an era of autonomy means a system that can take action on behalf of itself.

for memory for LLM applications, Retrieval-Augmented Generation (RAG), also known as semantic search, involves searching not by if-else logic but by using context.

We are proud to announce that we are working on something that will revolutionize the way businesses connect with their customers. We are a co-pilot for customer service that will allow to make messages and calls at scale autonomously.

so yeah it is all just experimentation. 

I will create whatever adds value to society, whether it is for-profit or Non-for Profit

Apart from that, we are also creating a community where like-minded people can come together and create something for the betterment of the country, for that we are partnering with a few companies and communities.

It’s a Lab about new cutting-edge Technologies.

it’s a lab about Education.